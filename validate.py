import os
import json
import gradio as gr
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from openai import OpenAI
from tqdm import tqdm
import io

# ================= é…ç½®åŒºåŸŸ =================
API_KEY = "sk-gfrwjhmclmjqofdvkhqkgkbpfcwvmygvaeuxpkansvtnowuf"
BASE_URL = "https://api.siliconflow.cn/v1"
MODEL_NAME = "moonshotai/Kimi-K2-Instruct-0905"

# Matplotlib å­—ä½“é…ç½®
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Microsoft YaHei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
# ===========================================

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

def load_json_or_jsonl(file_path):
    """
    æ™ºèƒ½åŠ è½½ï¼šå…¼å®¹æ ‡å‡† JSON (åˆ—è¡¨/å¯¹è±¡) å’Œ JSON Lines
    """
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()
        if not content:
            return []

        try:
            # å°è¯•ç›´æ¥åŠ è½½ (æ ‡å‡† JSON)
            parsed = json.loads(content)
            if isinstance(parsed, list):
                data = parsed
            elif isinstance(parsed, dict):
                data = [parsed]
        except json.JSONDecodeError:
            # å¤±è´¥åˆ™å°è¯•æŒ‰è¡ŒåŠ è½½ (JSONL)
            f.seek(0)
            lines = f.readlines()
            for line in lines:
                line = line.strip()
                if line:
                    try:
                        data.append(json.loads(line))
                    except:
                        pass
    return data

def llm_judge(question, gold, pred):
    """
    è°ƒç”¨ LLM åˆ¤æ–­æ­£ç¡®æ€§
    """
    gold_str = str(gold).strip()
    pred_str = str(pred).strip()

    # 1. å¿«é€Ÿé€šé“ï¼šå®Œå…¨åŒ¹é…
    if gold_str == pred_str:
        return True, "Exact Match"

    # 2. LLM è£åˆ¤é€šé“
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªå®¢è§‚çš„é˜…å·è€å¸ˆã€‚è¯·åˆ¤æ–­ã€è€ƒç”Ÿç­”æ¡ˆã€‘æ˜¯å¦ç¬¦åˆã€æ ‡å‡†ç­”æ¡ˆã€‘çš„æ„æ€ã€‚

    é¢˜ç›®: {question}
    æ ‡å‡†ç­”æ¡ˆ: {gold_str}
    è€ƒç”Ÿç­”æ¡ˆ: {pred_str}

    åˆ¤æ–­æ ‡å‡†ï¼š
    1. åªè¦è€ƒç”Ÿç­”æ¡ˆçš„æ ¸å¿ƒå«ä¹‰ä¸æ ‡å‡†ç­”æ¡ˆä¸€è‡´ï¼Œå³ä¸º Trueã€‚
    2. å¿½ç•¥æ ‡ç‚¹ã€å¤§å°å†™æˆ–æ— å…³çš„åºŸè¯ï¼ˆå¦‚"ç­”æ¡ˆæ˜¯..."ï¼‰ã€‚
    3. å¦‚æœæ•°å€¼ã€å®ä½“æˆ–å…³é”®æ—¶é—´ç‚¹é”™è¯¯ï¼Œå³ä¸º Falseã€‚

    è¯·ä»…å›å¤ "True" æˆ– "False"ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "You are a judge. Reply only True or False."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.01,
        )
        content = response.choices[0].message.content.strip().lower()
        is_correct = "true" in content
        return is_correct, "LLM Judged"
    except Exception as e:
        return False, f"Error: {str(e)}"

def evaluate_single_file(file_path, progress=gr.Progress()):
    """
    è¯„ä¼°å•ä¸ªä¸Šä¼ çš„æ–‡ä»¶
    """
    filename = os.path.basename(file_path)
    items = load_json_or_jsonl(file_path)

    if not items:
        return f"æ–‡ä»¶ {filename} ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯", None, None

    correct_count = 0
    total_count = 0
    details = []

    progress(0, desc=f"æ­£åœ¨è¯„ä¼° {filename}...")

    for idx, item in enumerate(items):
        q = item.get('question', '')
        gold = item.get('golden_answer', '')
        pred = item.get('agent_result', '')

        is_correct, reason = llm_judge(q, gold, pred)

        icon = "âœ…" if is_correct else "âŒ"
        detail = {
            "é¢˜å·": idx + 1,
            "ç»“æœ": icon,
            "é—®é¢˜": q[:50] + "..." if len(q) > 50 else q,
            "æ ‡å‡†ç­”æ¡ˆ": str(gold)[:30] + "..." if len(str(gold)) > 30 else str(gold),
            "é¢„æµ‹ç­”æ¡ˆ": str(pred)[:30] + "..." if len(str(pred)) > 30 else str(pred),
            "åˆ¤æ–­æ–¹å¼": reason
        }
        details.append(detail)

        if is_correct:
            correct_count += 1
        total_count += 1

        progress((idx + 1) / len(items), desc=f"æ­£åœ¨è¯„ä¼° {filename}... ({idx + 1}/{len(items)})")

    accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0

    summary = f"""
    ğŸ“Š **è¯„ä¼°ç»“æœæ‘˜è¦**

    æ–‡ä»¶å: {filename}
    æ€»é¢˜æ•°: {total_count}
    æ­£ç¡®æ•°: {correct_count}
    é”™è¯¯æ•°: {total_count - correct_count}
    æ­£ç¡®ç‡: {accuracy:.2f}%
    """

    return summary, accuracy, details, filename

def evaluate_multiple_files(files, progress=gr.Progress()):
    """
    è¯„ä¼°å¤šä¸ªä¸Šä¼ çš„æ–‡ä»¶å¹¶ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    """
    if not files:
        return "è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶", None

    stats = {}
    all_details = []

    for idx, file in enumerate(files):
        progress(idx / len(files), desc=f"å¤„ç†æ–‡ä»¶ {idx + 1}/{len(files)}")
        summary, accuracy, details, filename = evaluate_single_file(file.name, progress)

        # æå–æ–‡ä»¶åï¼ˆå»é™¤æ‰©å±•åï¼‰
        basename = os.path.splitext(filename)[0]
        stats[basename] = accuracy

        all_details.append(f"\n### {filename}\n{summary}\n")

    # ç”Ÿæˆå›¾è¡¨
    fig = create_comparison_chart(stats)

    combined_summary = "\n".join(all_details)

    return combined_summary, fig

def create_comparison_chart(stats):
    """
    åˆ›å»ºå¯¹æ¯”å›¾è¡¨
    """
    if not stats:
        return None

    filenames = list(stats.keys())
    accuracies = list(stats.values())

    fig = Figure(figsize=(12, 6))
    ax = fig.add_subplot(111)

    bars = ax.bar(filenames, accuracies, color='#4CAF50', edgecolor='black', alpha=0.8)

    ax.set_title('æµ‹è¯„æ­£ç¡®æ€§', fontsize=16, fontweight='bold')
    ax.set_xlabel('', fontsize=12)
    ax.set_ylabel('æ­£ç¡®ç‡ (%)', fontsize=12)
    ax.set_ylim(0, 115)
    ax.tick_params(axis='x', rotation=45)
    ax.grid(axis='y', linestyle='--', alpha=0.3)

    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height + 2,
                f'{height:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')

    fig.tight_layout()

    return fig

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="æµ‹è¯„æ­£ç¡®æ€§åˆ†æå·¥å…·", theme=gr.themes.Soft()) as app:
    gr.Markdown("""
    # ğŸ“Š æµ‹è¯„æ­£ç¡®æ€§åˆ†æå·¥å…·

    ä¸Šä¼  JSON æˆ– JSONL æ ¼å¼çš„æµ‹è¯„ç»“æœæ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯„ä¼°æ­£ç¡®æ€§å¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šã€‚

    ### ä½¿ç”¨è¯´æ˜ï¼š
    1. é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ª `.json` æˆ– `.jsonl` æ–‡ä»¶
    2. ç‚¹å‡»"å¼€å§‹è¯„ä¼°"æŒ‰é’®
    3. æŸ¥çœ‹è¯„ä¼°ç»“æœå’Œå¯è§†åŒ–å›¾è¡¨

    ### æ–‡ä»¶æ ¼å¼è¦æ±‚ï¼š
    æ¯æ¡è®°å½•éœ€åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
    - `question`: é—®é¢˜
    - `golden_answer`: æ ‡å‡†ç­”æ¡ˆ
    - `agent_result`: é¢„æµ‹ç­”æ¡ˆ
    """)

    with gr.Tab("å¤šæ–‡ä»¶å¯¹æ¯”è¯„ä¼°"):
        with gr.Row():
            file_input_multi = gr.File(
                label="ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
                file_count="multiple",
                file_types=[".json", ".jsonl"]
            )

        eval_btn_multi = gr.Button("ğŸš€ å¼€å§‹è¯„ä¼°", variant="primary", size="lg")

        with gr.Row():
            with gr.Column(scale=1):
                result_output_multi = gr.Markdown(label="è¯„ä¼°ç»“æœ")
            with gr.Column(scale=1):
                chart_output_multi = gr.Plot(label="æµ‹è¯„æ­£ç¡®æ€§")

    with gr.Tab("å•æ–‡ä»¶è¯¦ç»†è¯„ä¼°"):
        with gr.Row():
            file_input_single = gr.File(
                label="ä¸Šä¼ å•ä¸ªæ–‡ä»¶",
                file_count="single",
                file_types=[".json", ".jsonl"]
            )

        eval_btn_single = gr.Button("ğŸš€ å¼€å§‹è¯„ä¼°", variant="primary", size="lg")

        result_output_single = gr.Markdown(label="è¯„ä¼°ç»“æœæ‘˜è¦")

    # ç»‘å®šäº‹ä»¶
    eval_btn_multi.click(
        fn=evaluate_multiple_files,
        inputs=[file_input_multi],
        outputs=[result_output_multi, chart_output_multi]
    )

    eval_btn_single.click(
        fn=lambda file: evaluate_single_file(file.name)[0] if file else "è¯·ä¸Šä¼ æ–‡ä»¶",
        inputs=[file_input_single],
        outputs=[result_output_single]
    )

if __name__ == "__main__":
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ Gradio æµ‹è¯„åˆ†æå·¥å…·...")
    print("ğŸ“ è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://127.0.0.1:7860")
    app.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        show_error=True,
        inbrowser=True  # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    )
